{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_raw_data = '../data/ordered_ex1_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_df = pd.read_csv(local_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target (percentage of having adverse events) = number_of_sae_subjects / enrollment\n",
    "raw_data_df['target'] = raw_data_df['number_of_sae_subjects'] / raw_data_df['enrollment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop number_of_sae_subjects and enrollment\n",
    "raw_data_df.drop(raw_data_df.columns[[7,8]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframe to ndarray\n",
    "raw_data = raw_data_df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map has_us_facilities value ('t','f') -> (1, 0)\n",
    "raw_data[raw_data[:,4] == 't',4]= 1\n",
    "raw_data[raw_data[:,4] == 'f',4]= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_category(id_cat):\n",
    "    output = []\n",
    "    prev_id = None\n",
    "    tmp = {}\n",
    "    for nct_id, cat in id_cat:\n",
    "        if prev_id is None or prev_id == nct_id:\n",
    "            if prev_id is None:\n",
    "                prev_id = nct_id\n",
    "            tmp[cat] = 1\n",
    "        else:\n",
    "            output.append(tmp)\n",
    "            # reset\n",
    "            tmp = {}\n",
    "            tmp[cat] = 1\n",
    "            prev_id = nct_id\n",
    "    output.append(tmp)\n",
    "    print('output number of merged unique ids: {}'.format(len(output)))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert conditions, interventions and countries to hash feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique nct_ids: 16677\n"
     ]
    }
   ],
   "source": [
    "unique_ids = np.unique(raw_data[:,0])\n",
    "number_of_uniqueID = unique_ids.shape[0]\n",
    "print('number of unique nct_ids: {}'.format(number_of_uniqueID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = raw_data[:,[0,1]]\n",
    "interventions = raw_data[:,[0,2]]\n",
    "countries = raw_data[:,[0,5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TODO: draw frequency distribution of the three features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ganciclovir', 'ganciclovir', 'ganciclovir', ..., 'oxycodone',\n",
       "       'fentanyl', 'adenosine'], dtype=object)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interventions[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output number of merged unique ids: 16677\n",
      "output number of merged unique ids: 16677\n",
      "output number of merged unique ids: 16677\n"
     ]
    }
   ],
   "source": [
    "# preprocess the high dimentional features before feed into feature hasher\n",
    "merged_conditions = merge_category(conditions)\n",
    "merged_interventions = merge_category(interventions)\n",
    "merged_countries = merge_category(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique conditions: 1909\n",
      "number of unique interventions: 1846\n",
      "number of unique countries: 142\n"
     ]
    }
   ],
   "source": [
    "number_of_conditions = np.unique(conditions[:,1]).shape[0]\n",
    "print('number of unique conditions: {}'.format(number_of_conditions))\n",
    "\n",
    "number_of_interventions = np.unique(interventions[:,1]).shape[0]\n",
    "print('number of unique interventions: {}'.format(number_of_interventions))\n",
    "\n",
    "number_of_countries = np.unique(countries[:,1]).shape[0]\n",
    "print('number of unique countries: {}'.format(number_of_countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature hasher\n",
    "conditions_hasher = FeatureHasher(n_features=int(number_of_conditions * 0.2),\n",
    "                                                             non_negative=True,input_type='dict')\n",
    "interventions_hasher = FeatureHasher(n_features=int(number_of_interventions * 0.2),\n",
    "                                                             non_negative=True,input_type='dict')\n",
    "countries_hasher = FeatureHasher(n_features=int(number_of_countries),\n",
    "                                                             non_negative=True,input_type='dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditions_feature shape: (16677, 381)\n",
      "interventions_feature shape: (16677, 369)\n",
      "countries_feature shape: (16677, 142)\n"
     ]
    }
   ],
   "source": [
    "# apply feature hashing\n",
    "conditions_feature = conditions_hasher.fit_transform(merged_conditions).toarray()\n",
    "print('conditions_feature shape: {}'.format(conditions_feature.shape))\n",
    "\n",
    "interventions_feature = interventions_hasher.fit_transform(merged_interventions).toarray()\n",
    "print('interventions_feature shape: {}'.format(interventions_feature.shape))\n",
    "\n",
    "countries_feature = countries_hasher.fit_transform(merged_countries).toarray()\n",
    "print('countries_feature shape: {}'.format(countries_feature.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1846,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(interventions[:,1]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending the hashed feature to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NCT00000143', 'hiv infections', 'ganciclovir', 19, 1,\n",
       "       'United States', 1, 0.0], dtype=object)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstructed training data shape: (16677, 897)\n"
     ]
    }
   ],
   "source": [
    "# drop the old conditions, interventions and countries\n",
    "prev_id = None\n",
    "new_data = []\n",
    "tmp = []\n",
    "idx = 0\n",
    "for data in raw_data:\n",
    "    cur_id = data[0]\n",
    "    if prev_id is None or cur_id != prev_id:\n",
    "        tmp.append(cur_id)\n",
    "        tmp.append(data[3])\n",
    "        tmp.append(data[4])\n",
    "        tmp.append(data[6])\n",
    "        \n",
    "        tmp += conditions_feature[idx].tolist()\n",
    "        tmp += interventions_feature[idx].tolist()\n",
    "        tmp += countries_feature[idx].tolist()\n",
    "        \n",
    "        tmp.append(data[7])\n",
    "        \n",
    "        new_data.append(tmp)\n",
    "        \n",
    "        # update\n",
    "        prev_id = cur_id\n",
    "        tmp = []\n",
    "        idx += 1\n",
    "\n",
    "# new data shape: nct_id, number_of_facilities, has_us_facility, \n",
    "# number_of_sponsors, conditions_features, interventions_features, contries_features, percentage_of_adverse_event (target)\n",
    "new_data = np.array(new_data)\n",
    "print('reconstructed training data shape: {}'.format(new_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> note: remove the first nct_id column before send to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly shuffle the data before categorization\n",
    "np.random.shuffle(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['NCT00000143', '19', '1', ..., '0.0', '0.0', '0.0'],\n",
       "       ['NCT00000378', '1', '1', ..., '0.0', '0.0', '0.0'],\n",
       "       ['NCT00000620', '7', '1', ..., '0.0', '0.0', '0.0'],\n",
       "       ...,\n",
       "       ['NCT01295320', '11', '0', ..., '0.0', '0.0', '0.0'],\n",
       "       ['NCT01295814', '1', '1', ..., '0.0', '0.0', '0.0'],\n",
       "       ['NCT01295840', '1', '0', ..., '0.0', '0.0', '0.0']], dtype='<U22')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(new_data.shape[0] * 0.7)\n",
    "train_features  = new_data[:train_size, :-1]\n",
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features shape: (11673, 896)\n",
      "validation_features shape: (3335, 896)\n",
      "test_features shape: (1669, 896)\n"
     ]
    }
   ],
   "source": [
    "train_size = int(new_data.shape[0] * 0.7)\n",
    "train_features  = new_data[:train_size, :-1]\n",
    "train_labels = new_data[:train_size, -1]\n",
    "print('train_features shape: {}'.format(train_features.shape))\n",
    "\n",
    "validation_size = int(new_data.shape[0] * 0.2)\n",
    "validation_features = new_data[train_size:train_size + validation_size, :-1]\n",
    "validation_labels = new_data[train_size:train_size + validation_size, -1]\n",
    "print('validation_features shape: {}'.format(validation_features.shape))\n",
    "\n",
    "test_features = new_data[train_size + validation_size:, :-1]\n",
    "test_labels = new_data[train_size + validation_size:, -1]\n",
    "print('test_features shape: {}'.format(test_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Convertion\n",
    "convert the numpy array into recordIO-protobuf or CSV format that can be used by sagemaker linear_learner\n",
    "model specs: https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
